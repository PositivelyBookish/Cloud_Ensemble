# -*- coding: utf-8 -*-
"""Convnext-Tiny

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i5OLU7fy2y4IcZnZLIM0fUcTSCR25JO0
"""

import torch
from torch import nn
from torchvision import transforms, models
from torch.utils.data import DataLoader, Dataset
from PIL import Image

# Constants and parameters
IMAGE_SIZE = 224  # ConvNeXt-Tiny default input size
classification_types = [
    'Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy',
    'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy',
    'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight',
    'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot',
    'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato__Target_Spot',
    'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato__Tomato_mosaic_virus',
    'Tomato_healthy'
]

# Path to the pre-trained model
model_path = '../models/convnext_tiny-model-89.pth'  # Update this path

# Initialize ConvNeXt-Tiny
model = models.convnext_tiny(pretrained=False)
model.classifier[2] = nn.Linear(model.classifier[2].in_features, len(classification_types))  # Modify final layer for 15 classes

# Load the pre-trained model state dict
state_dict = torch.load(model_path, map_location=torch.device('cpu'))
if 'classifier.2.weight' in state_dict:
    del state_dict['classifier.2.weight']
if 'classifier.2.bias' in state_dict:
    del state_dict['classifier.2.bias']
model.load_state_dict(state_dict, strict=False)

# Freeze feature extraction layers
for param in model.features.parameters():
    param.requires_grad = False

# Set model to evaluation mode
model.eval()

# Image transformations for ConvNeXt
transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),  # Resize to ConvNeXt's input size
    transforms.ToTensor(),                       # Convert to tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet stats
])

# Create a custom Dataset for a single image or small set of images
class CustomImageDataset(Dataset):
    def __init__(self, image_paths, transform=None):
        self.image_paths = image_paths
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image, idx  # Return index for easy tracking during prediction

# Example: List of image paths (just one image in this case)
image_paths = ["../test_images/Tomato___Tomato_mosaic_virus.jpg"]  # Update with the path to your input image
dataset = CustomImageDataset(image_paths, transform)
dataloader = DataLoader(dataset, batch_size=1, shuffle=False)

# Fine-tune the model on a small dataset (or single image)
def fine_tune_on_single_image(model, dataloader, num_epochs=10, lr=1e-4):
    """
    Fine-tunes the ConvNeXt model on a single image or small dataset.

    Parameters:
        model (nn.Module): ConvNeXt model to fine-tune.
        dataloader (DataLoader): DataLoader for the input image(s).
        num_epochs (int): Number of epochs for fine-tuning.
        lr (float): Learning rate.

    Returns:
        nn.Module: Fine-tuned model.
    """
    # Unfreeze all layers for fine-tuning
    for param in model.features.parameters():
        param.requires_grad = True

    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)
    criterion = nn.CrossEntropyLoss()

    # Fine-tune for a few epochs
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for inputs, _ in dataloader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, torch.tensor([0]))  # Assume the true label is 0 (can be changed for specific task)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        print(f"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}")

    return model

# Fine-tune on the small dataset (single image)
model = fine_tune_on_single_image(model, dataloader, num_epochs=10, lr=1e-5)

# Prediction function for fine-tuned model
def predict_image(model, image_path):
    """
    Predict the class of a single image after fine-tuning the model.

    Parameters:
        model (nn.Module): The fine-tuned model.
        image_path (str): Path to the image.

    Returns:
        str: Predicted class name.
        float: Confidence score (percentage).
    """
    # Load image and transform
    image = Image.open(image_path).convert("RGB")
    input_tensor = transform(image).unsqueeze(0)  # Add batch dimension

    # Perform prediction
    model.eval()
    with torch.no_grad():
        output = model(input_tensor)

    # Get the predicted class and confidence
    _, predicted_class = torch.max(output, 1)
    confidence = torch.softmax(output, dim=1)[0, predicted_class].item()

    predicted_label = classification_types[predicted_class.item()]
    return predicted_label, confidence * 100

# Example prediction on the input image
image_path = "../test_images/Tomato___Tomato_mosaic_virus.jpg"  # Update with the input image path
predicted_label, confidence = predict_image(model, image_path)
print(f"Predicted Class: {predicted_label}")
print(f"Confidence: {confidence:.2f}%")